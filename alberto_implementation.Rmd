---
title: "alberto_implementation"
author: "Niek Brouwer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this document we apply the method developed by Gil-Jimenez et al. to the METABRIC breast cancer cohort. The spatial coordinates and phenotype classification of single cells is retrieved from the paper by Danenberg et al. (2022).

```{r libraries and settings, message=FALSE}
# invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))

library(here)
library(fst)
library(data.table)
library(ggplot2)
library(assertthat)
source(here("UtilityFunctions.R"))
library(tictoc)

cells <- getCells()
phenotype_list <- get_phenotypes()

library(tidyverse)
library(ggpubr)
library(readxl)
library(reshape2)
library(dbscan)
library(broom)
library(zoo)
library(knitr)
library(NMF,quietly = T)
library(MASS)
library(car)
library(doParallel)
library(foreach)
library(spatstat)
# library(raster)
library(gridExtra)


```

```{r, message=FALSE}
# Unregister open clusters
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

unregister_dopar()
```


## 1-NN distance computation
Alberto uses two input files:
* A cell dataframe with columns: "tnumber', "analysisregion", "layer", "Xmin", "Xmax", "Ymin", "Ymax", "Xcenter", "Ycenter", "phenotype", "cellarea"
* A tissue area dataframe with columns:"tnumber', "Tumor.Area.mm2", "Stroma.Area.mm2", "Total.Area"

We miss some of this information. We only have cell centroid coordinates and we don't have tissue area.


```{r filtering and cleaning}
# Rename labels to fit methods of Alberto
cells <- cells %>% rename(tnumber = ImageNumber)
cells <- cells %>% rename(phenotype = meta_description)
cells <- cells %>% rename(Xcenter = Location_Center_X)
cells <- cells %>% rename(Ycenter = Location_Center_Y)

# Remove unncessary attributes
cells <- cells[,c("tnumber", "ObjectNumber", "Xcenter", "Ycenter", "phenotype", "AreaShape_Area")]
```

```{r data exploration}
counts <- cells %>% count(tnumber, phenotype)
#Calculate median value
counts%>%
group_by(phenotype)%>% 
summarise(Mean=mean(n), Max=max(n), Min=min(n), Median=median(n), Std=sd(n))

LowDF <- counts%>%
group_by(phenotype)%>% filter(median(n) <= 20)
HighDF <- counts%>%
group_by(phenotype)%>% filter(median(n) > 20)

ggplot(counts) + geom_bar(aes(x=phenotype, y=n, fill=tnumber), stat="identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Number of cells per phenotype")

ggplot(counts, aes(x=phenotype, y=n)) + 
    geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Number of cells per phenotype")

ggplot(HighDF, aes(x=phenotype, y=n)) +
  geom_boxplot(outlier.shape = NA) + coord_cartesian(ylim =  c(0, 300)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Phenotypes with high number of cells")

ggplot(LowDF, aes(x=phenotype, y=n)) +
  geom_boxplot(outlier.shape = NA) + coord_cartesian(ylim =  c(0, 300)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Phenotypes with low number of cells")

```

Compute all 1-NN distances.

```{r 1-NN distances}
tic('1-NN distances')
# call cores (parallelization)
# Comment this because of limitation on core usability in darwin
cores=detectCores()
cl <- makeCluster(floor(cores[1]/4))
registerDoParallel(cl)

# First NNdist all-against-all phenotypes
#' @param x Multiplex immunofluorescence coordinate dataframe (with Xcenter, Ycenter, phenotype, etc)
#' @param phenotype1 Phenotype From
#' @param phenotype2 Phenotype To
distances <- function(x, phenotype1,phenotype2) {
  # Create a point pattern
  spdat <- ppp(
    x = x$Xcenter,
    y = x$Ycenter,
    window = owin(
      xrange = c(min(x$Xcenter), max(x$Xcenter)),
      yrange = c(min(x$Ycenter), max(x$Ycenter))
    ),
    marks = x$phenotype
  )
  phenos <- unique(x$phenotype)
  
  #if phenotypes to compare are equal, then the 2nd nearest neighbour must be used, else the current point is compared to itself
  if(phenotype1 != phenotype2){
    res <- nncross(spdat[which(spdat$marks == phenotype1)], spdat[which(spdat$marks == phenotype2)], k = 1, what = 'dist')
  } else {
    res <- nncross(spdat[which(spdat$marks == phenotype1)], spdat[which(spdat$marks == phenotype2)], k = 2, what = 'dist')
    
  }
  return(res)
}

# Define which phenotypes will be studied (UNIQUE CELL TYPES IN YOUR DATASET)
# phenotypes <- unique(cells$phenotype) #All cell types
phenotypes <- unique(phenotype_list$stromal_immune$pg_id_map$meta_description)[1] #Take only 1 for debugging
print(paste0("The phenotypes we are considering: ", paste(phenotypes,collapse = ', ')))

# Compute 1-NN for all combinations of samples (n=24) x phenotype FROM (n=7) x phenotype TO (n=7)
spatresall <-
  foreach(i = unique(cells %>% pull(tnumber)),
          .packages = c('sp', 'spatstat'),
          .final = function(x) setNames(x, unique(cells %>% pull(tnumber)))) %dopar% {
            x <- cells[which(cells$tnumber == i),] 
            phenotypes <- setNames(phenotypes, phenotypes)
            spres <-
              lapply(phenotypes, function(p1) {
                lapply(phenotypes, function(p2) {
                  distances(x, p1, p2)
                })
              })
            return(spres)
          }

stopCluster(cl)

toc()
```

Clean-up.

```{r}
#Reshape hot mess of lists of lists of lists into long data frame.
dfl <- lapply(spatresall, function(tnr){
  lapply(tnr, function(p1){
    rbindlist(lapply(p1,function(Distance) {
      as.data.frame(Distance)
    }), idcol = "phenotype_to")
  })
})

dfl2 <- lapply(dfl, function(tnr){
  rbindlist(tnr, idcol = "phenotype_from")
})

dfl3 <- rbindlist(dfl2, idcol = "tnumber")

#add pseudocounts on distances for log transform
#1 pixel = 1 micron
dfl3$Distance <- (dfl3$Distance + 1)

NNdistances <- dfl3

# free up some memory. these temps are no longer needed
rm(dfl)
rm(dfl2)
rm(dfl3)
gc() # do garbage collection to free up memory
```

### Boxplot of distances
```{r}
ggplot(NNdistances, aes(x=phenotype_from, y=Distance)) + 
    geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(NNdistances, aes(x=phenotype_to, y=Distance)) + 
    geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


Estimate 1-NN distance distribution by grouping distances in bins.

```{r}
options(dplyr.summarise.inform = FALSE)

tic('bin smoothing')
# Explore data from 0 to 300 microns
SlidingBins_300 <- rollapply(c(0:300),5,function(y) { return(c(min(y),max(y)))})

CountRows <- function(x) {
  cnt <- apply(SlidingBins_300,1, function(y) {nrow(x[which(x$Distance >= y[1] & x$Distance <= y[2])])})
  return(cnt)
}

BinCounts_300 <- apply(SlidingBins_300, 1, function(x) {
  CurrentWindow <- subset(NNdistances, Distance >= x[1] & Distance <= x[2])
  GroupCounts <- CurrentWindow %>% group_by(tnumber, phenotype_from, phenotype_to) %>%
    dplyr::summarise(N = dplyr::n())
  return(GroupCounts)
})

names(BinCounts_300) <- c(1:297)
dfslides_300 <- as.data.frame.matrix(SlidingBins_300)
dfslides_300$V3 <- apply(dfslides_300,1,mean)
dfslides_300$ID <- row.names(dfslides_300)

LongBinCounts_300 <- bind_rows(BinCounts_300, .id = "nth_window")
# WinMean is the X coordinate of your "calculated histogram"
LongBinCounts_300$WinMean <- dfslides_300$V3[match(LongBinCounts_300$nth_window, dfslides_300$ID)]

# Area not available, so compute with max and min x and y coordinate
# ALTERNATIVE METHOD? CONVEX HULL
areas <- left_join(aggregate(Xcenter ~ tnumber, cells, function(x) min(x)),
                   aggregate(Xcenter ~ tnumber, cells, function(x) max(x)), by='tnumber')
areas <- left_join(areas,aggregate(Ycenter ~ tnumber, cells, function(x) min(x)), by='tnumber')
areas <- left_join(areas,aggregate(Ycenter ~ tnumber, cells, function(x) max(x)), by='tnumber')
areas$area <- (areas[,3]-areas[,2])*(areas[,5]-areas[,4])*0.001 #area in mm

# Match total areas of the tissue 
LongBinCounts_300$tnumber <- as.integer(LongBinCounts_300$tnumber)
LongBinCounts_300$Area <- LongBinCounts_300 %>%
  left_join(data.frame(areas), by='tnumber') %>%
  mutate(Area=area) %>% pull(Area)

# N.per.mm2 is the Y coordinate of your "calculated histogram"
# Normalize for area
# LongBinCounts_300$N.per.mm2 <- LongBinCounts_300$N / LongBinCounts_300$Area
# Might not be necessary due to AUC normalization [COMPARE]
LongBinCounts_300$N.per.mm2 <- LongBinCounts_300$N

# Function to compute Area under the curve 
funAUC <- function(x,y){
  id <- order(x)
  AUC <- sum(diff(x[id]) * rollmean(y[id],2))
  return(AUC)
}

AUCScaledSlides_300 <- LongBinCounts_300 %>%
  dplyr::group_by(phenotype_from, phenotype_to, tnumber) %>%
  dplyr::mutate(N.per.mm2.scaled = N.per.mm2 / funAUC(WinMean, N.per.mm2))

stopifnot(!(Inf %in% AUCScaledSlides_300$N.per.mm2.scaled))

# Sometimes there are Infinite values here in case of small number of cells
# Remove these samples
# AUCScaledSlides_300 <- AUCScaledSlides_300[!is.infinite(AUCScaledSlides_300$N.per.mm2.scaled),]

#double check if the AUC of AUCs is 1
AUCcheck <- AUCScaledSlides_300 %>%
  dplyr::group_by(phenotype_from, phenotype_to, tnumber) %>%
  dplyr::mutate(AUC = funAUC(WinMean, N.per.mm2.scaled))
stopifnot(length(unique(lapply(unique(AUCcheck$AUC), round)))==1)

#save this
write_delim(AUCScaledSlides_300 %>% 
              mutate(phenotype_combo=paste(phenotype_from,phenotype_to,sep='_to_')), paste(here('scratch/AUCScaledSlides_300'), '.tsv', sep=''),delim='\t')

toc()
```


## Parameter estimation
From the distance bin collection, we try to estimate a distribution.

```{r load packages 2, message=FALSE, warning=FALSE}
invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))

library(ComplexHeatmap)
library(tidyverse)
library(plyr)
library(cold) #function fixeff()
library(lme4)
library(glmmTMB)
library(fitdistrplus)
library(tidyr)
library(cold)
library(broom)
library(ggpubr) # stat_compare_means
library(here)
library(fst)
library(doParallel)

library(data.table)
library(ggplot2)
library(assertthat)
library(tictoc)
source(here("UtilityFunctions.R"))
```


```{r estimate parameters}
tic('parameter initialization')
all_distances_data <- read_delim(here('scratch/AUCScaledSlides_300.tsv'),delim='\t',
                                 col_types=list(tumor_stroma=col_character()))

all_distances_data <- all_distances_data %>% as_tibble %>% 
  mutate(distance_window = WinMean) %>% 
  mutate(phenotype_combo = paste(phenotype_from, phenotype_to, sep='_to_')) %>% 
  dplyr::select(tnumber, phenotype_combo, `N.per.mm2.scaled`, distance_window) %>%
  mutate(new = `N.per.mm2.scaled` * 1000) %>%
  mutate(new =round(new))


# Recreate 1-NN histogram from coordinates (this is required for function "fitdistrplus")
# PARALLELIZED
cores=detectCores()
cl <- makeCluster(floor(cores[1]/4)) #not to overload
registerDoParallel(cl)

all_combos_dists <- foreach(tn = unique(all_distances_data %>% pull(tnumber)), .combine=rbind, .packages="tidyverse") %dopar% {
  for(combo in unique(all_distances_data %>% pull(phenotype_combo))){
    all_dists_tnum <- list()
    dists <- c(1,all_distances_data %>% filter(tnumber == tn) %>% filter(phenotype_combo == combo) %>% pull(distance_window) )
    times <- c(1, all_distances_data %>% filter(tnumber == tn) %>% filter(phenotype_combo == combo) %>% pull(new))

    if(length(times) == 0){
      dists <- c(1:298)
      times <- rep(0,length(c(1:298)))
    }

    for(i in 1:length(times)){
      all_dists_tnum <- c(all_dists_tnum, rep(dists[i], times[i]))
    }

    aldists <- unlist(all_dists_tnum %>% as.numeric)
    aldistsdf <- as_tibble(data.frame(dists = aldists,
                                      tnumber = rep(tn, length(aldists)),
                                      combo = rep(combo, length(aldists))))

  }
  aldistsdf
}


# Fit a Weibull distribution by Maximum likelihood (this is an initial estimation)
initial_params <- data.frame(matrix(ncol=5, nrow=0))
colnames(initial_params) <- c('term','estimate','std.error', 'tnumber','combo')
initial_params <- initial_params %>% 
  mutate(term=as.character(term), estimate=as.numeric(estimate), `std.error`=as.numeric(`std.error`),tnumber=as.numeric(tnumber),
         combo=as.character(combo))


stopCluster(cl)


## POSSIBLE TO PARALLELIZE
initial_params <- data.frame(matrix(ncol=5, nrow=0))
colnames(initial_params) <- c('term','estimate','std.error', 'tnumber','combo')
initial_params <- initial_params %>% 
  mutate(term=as.character(term), estimate=as.numeric(estimate), `std.error`=as.numeric(`std.error`),tnumber=as.numeric(tnumber),
         combo=as.character(combo))
for(combo in unique(all_distances_data %>%  pull(phenotype_combo))){
  # for different "tnumber"
  message(combo)
  for(tn in unique(all_combos_dists  %>% pull(tnumber))){
        # take into account only 1-NN dists < 100, because of the precision of fitdists (no of bins in histogram)
    # EXCEPT for From/To PanCK or negative
    # the parameters will be further optimized later
    
  # There are some instances that have only 1 sample or where the parameters cannot be estimated
    tryCatch({
    if(str_detect(combo, 'PanCK\\+_') | str_detect(combo, 'negative_')){
      params <- fitdist(all_combos_dists %>%
                          filter(combo == combo) %>% filter(tnumber == tn)  %>%
                          pull(dists) ,"weibull") %>% summary
    } else{
      params <- fitdist(all_combos_dists %>%
                          filter(combo == combo) %>% filter(tnumber == tn) %>% filter(dists < 100) %>%
                          pull(dists) ,"weibull") %>% summary
    }
    class(params) <- c("fitdist", "fitdistr")
    params <- broom::tidy(params)
    params <- params %>% mutate(tnumber=rep(tn,nrow(params))) %>%
      mutate(combo=rep(combo,nrow(params)))
    initial_params <- bind_rows(initial_params, params)
    }, error=function(e){})
  }
}

initial_params_weib <- initial_params

write_delim(initial_params_weib, here('scratch/initial_params_weib_stromalImmune.tsv'),delim='\t')

toc()

```
Take a look at the initial parameter estimation.
```{r}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```


```{r}
# Fit raw normalized data with weibull distribution with initial paraneters
plts <- list()
for (t in 1:20){
  for (c in unique(all_distances_data$phenotype_combo)){
      hist <- ggplot(all_distances_data[all_distances_data$tnumber == t & all_distances_data$phenotype_combo == c ,]) +
        geom_bar(aes(x=distance_window, y=N.per.mm2.scaled), stat="identity") +
        stat_function(fun = dweibull, args = list(shape = initial_params_weib[initial_params_weib$tnumber==t & initial_params_weib$term=='shape','estimate'],
                                                  scale = initial_params_weib[initial_params_weib$tnumber==t & initial_params_weib$term=='scale','estimate'])) + ggtitle(paste("tnumber: ", t, "combi: ", c))
  
    print(hist)
  }
}


```


## Fitting NLME model
Now we fit a Weibull function using a nonlinear-mixed fixed effect model to the 1-NN distance distribution.

```{r load packages 3, message=FALSE, warning=FALSE}
invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))

library(tidyverse)
library(ggpubr)
library(readxl)
library(reshape2)
library(dbscan)
library(broom)
library(zoo)
library(knitr)
library(magrittr)
library(NMF,quietly = T)
library(MASS)
library(car)
library(doParallel)
library(stats)
library(foreach)
library(spatstat)
# library(raster)
library(nlme)
library(dplyr)
library(gridExtra)
library(here)
library(tictoc)
```


```{r NLME model presettings}
initial_params <- read_delim(here('scratch/initial_params_weib_stromalImmune.tsv'),delim='\t')

# Calculate number of cells for each cell type / sample (will be used later for filtering purposes)
n_cells <- aggregate(cells$phenotype, by=list(cells$tnumber,cells$phenotype), FUN=length)
colnames(n_cells) <- c('tnumber', 'phenotype', 'n')

xy_data_exc_oct <- read_delim(here('scratch/AUCScaledSlides_300.tsv'),delim='\t') %>%
  mutate(distance_window = WinMean) %>%
  mutate(x=distance_window, y=`N.per.mm2.scaled`) 

threshold_pixels <- 300
threshold_microns <- threshold_pixels

# Define maximum Shape (A_max) and maximum Scale (B_max) parameters for your fits
B_max <- 500 # max scale parameter (0,500]
A_max <- 10  # max shape parameter (0,10]

# Define Weibull and parameterized Weibull functions, and functions to convert between parameterized and
## non parameterized Weibull
## (Parameterization was done to ease the fitting procedure, in a non-restricted manner)
convert_params <- function(a,b){
  A=-log(A_max/a - 1)
  A = as.numeric(A)
  B=-log(B_max/b-1)
  B = as.numeric(B)
  return(c(A=A,B=B))
}

convert_params_reverse <- function(A,B){
  a=A_max/(1+exp(-A))
  b=B_max/(1+exp(-B))
  return(c(a=a,b=b))
}
# Define Weibull distribution function in a parameterized way:
nform2 <- ~(( ( A_max/(1+exp(-A)) )  / ( B_max/(1+exp(-B)) )) * (( x/( B_max/(1+exp(-B))) )^(( A_max/(1+exp(-A)) )-1)) * exp(-1* (x/( B_max/(1+exp(-B))))^( A_max/(1+exp(-A)) )))

weibfunc2 <- function(x,A,B){
  a = A_max/(1+exp(-A))
  b = B_max/(1+exp(-B)) 
  return(((a/b) * ((x/b)^(a-1)) * exp(- (x/b)^a)))
}

nfun2 <- deriv(nform2,namevec=c("A","B"),
               function.arg=c("x","A","B"))

```


```{r fit NLME}
# Define function to fit a Weibull model to x/y coordinates of normalized 1-NN distance
## distribution coordinates, filtering out samples with n_cells < threshold_filter_cells
#' @param xy_coordinates_curves 1-NN distribution coordinate dataframe
#' @param combi Cell combination of interest: 'CellFROM_to_CellTO'
#' @param n_cells_df Dataframe with number of cells per sample (for each cell type)
#' @param threshold_filter_cells Threshold to filter out samples depending on the cell number
#' @param initial_params_df Dataframe with initial Weibull parameters
fit_data <- function(xy_coordinates_curves, combi, n_cells_df, threshold_filter_cells,
                     initial_params_df){
  message(combi)
  xy_data_filt <- xy_coordinates_curves %>% filter(phenotype_combo == combi) %>% as_tibble
  
  xy_data_filt <- xy_data_filt %>% 
    left_join(n_cells_df %>% mutate(n_from=n) %>% dplyr::select(-n), by=c('tnumber','phenotype_from'='phenotype')) %>%
    left_join(n_cells_df %>% mutate(n_to=n) %>% dplyr::select(-n), by=c('tnumber','phenotype_to'='phenotype'))
  
  threshold_cells <- threshold_filter_cells
  message(xy_data_filt %>% filter(n_from<=threshold_cells & n_to <= threshold_cells) %>%
            mutate(tnumber=paste(tnumber, 'nFROM', as.character(n_from), 'nTO',as.character(n_to))) %>% 
            pull(tnumber) %>% unique %>% paste(collapse=' / '))
  
  xy_data_filt <- xy_data_filt %>% filter(n_from>threshold_cells & n_to > threshold_cells)
  
  # Add missing observations in data and set to 0
  ## i.e. if no distances were observed beyond 100 microns, the normalized scaled counts 
  ## from 100 to 300 microns will be set to 0 
  # include 0,0 or only 1,0??
  xy_data_filt <- expand.grid(x=c(1,xy_data_filt %>%pull(distance_window) %>% unique), 
                              tnumber=xy_data_filt %>%pull(tnumber) %>% unique,
                              phenotype_combo=combi) %>%
    left_join(xy_data_filt, by=c('x','tnumber', 'phenotype_combo')) %>%
    mutate(y=ifelse(is.na(y),0,y))
  
  mean_params <- initial_params_df %>% filter(combo == combi) %>%
    filter(tnumber %in% unique(xy_data_filt$tnumber)) %>% 
    group_by(term) %>% dplyr::summarise(mean_estimate = mean(estimate))
  
  start_params <- c(a=mean_params %>% filter(term == 'shape') %>% pull(mean_estimate),
                    b=mean_params %>% filter(term == 'scale') %>% pull(mean_estimate))

  if(combi == 'PanCK+_to_PanCK+'){
    start_params <- c(a=3, b=10) # rewrite exception imsicion for pck-pck
  }
  
  fit52_oct <- tryCatch({
    nlme(y~nfun2(x,A,B),
         fixed=A+B~1,
         random=list(tnumber=pdDiag(A+B~1)), # or pdDiag, pdLogChol
         data=xy_data_filt %>% mutate(tnumber = factor(tnumber)),
         start=convert_params(start_params['a'], start_params['b']),
         method='REML', control = nlmeControl(maxIter = 1000, 
                                              returnObject = F,
                                              msMaxIter=200,
                                              pnlsTol=1e-1, 
                                              tolerance=1e-6, opt="nlm"))
  },
  error=function(cond){
    message(paste('failed',combi))
    return(combi)
  })
  # }
  return(list(model=fit52_oct, xy_data=xy_data_filt))
  
}
```

# Implement pipeline
* First try to fit models for ALL data
* If for a particular phenotype combo it doesn't work, fit:
* Fit all data with n_cells > 20
* If not, increase the threshold from 20 to 100

```{r NLME for all phenotypes}
tic('Weibull parameter estimation')
# Define phenotype combinations to study in data
combinations_to_study <- unique(xy_data_exc_oct %>% pull(phenotype_combo))

success_models <- list() # Fitted models

# Dataframe to store fitted Weibull coefficients
weib_coefs <- data.frame(matrix(nrow=0,ncol=4))
colnames(weib_coefs) <- c('a','b','sample','phenotype_combo')
weib_coefs$a %<>% as.numeric()  # shape
weib_coefs$b %<>% as.numeric()  # scale
weib_coefs$sample %<>% as.character()
weib_coefs$phenotype_combo %<>% as.character()

# Function to store x/y coordinates used for modelling
xy_data_weib <- xy_data_exc_oct %>% slice(0)
xy_data_weib <- xy_data_weib %>% add_column(yhat=as.numeric())

# Function to iterate through pheno combos
subset_combinations <- combinations_to_study
# Iterate through different number of threshold minimum number of cells sample
## (in some cases, all samples word, in other strenghter filter need to be 
## applied to samples with low number of cells)

for(threshold_cells in c(0,20,50,70,100)){
  model_objects <- list()
  if(length(subset_combinations) > 0){
    ## POSSIBLE TO PARELLELIZE
    for(combi in subset_combinations){
      message(threshold_cells)
      # Fit Weibull distribution
      ## If fit succeeds, a nlme model is returned, otherwise a character
      ## with the name of the failed phenotype combination is returned
      pipeline_run <- fit_data(xy_data_exc_oct, combi, n_cells, 
                               threshold_cells, initial_params)
      model_objects <- append(model_objects,
                              list(combi=pipeline_run[['model']]))
      fitted_model <- tail(model_objects, 1)[[1]] # retrieve fitted model in the for loop
      # If the model successfully fitted, append estimated parameters of the model                        
      # if(class(fitted_model)  != 'character'){
      if(!is(fitted_model, 'character')){
        # Weibull parameters:
        new_data_weib_param <- as_tibble(ranef(fitted_model)) %>%
          mutate(sample=rownames(ranef(fitted_model))) %>%
          mutate(A=A + fixef(fitted_model)['A'],
                 B=B+ fixef(fitted_model)['B']) %>%
          mutate(phenotype_combo=combi) %>%
          mutate(a=10/(1+exp(-A)),b=500/(1+exp(-B)))
        weib_coefs <- bind_rows(weib_coefs, new_data_weib_param)
        
        # x/y coordinates of input / output model: 
        xy_data_weib <- bind_rows(xy_data_weib,
                                      pipeline_run[['xy_data']] %>% mutate(yhat=fitted(fitted_model)))
      }
    }
  }
  names(model_objects) <- subset_combinations
  # Update subset combinations. Include only phenotype combinations whose modelling failed
  subset_combinations <- names(model_objects)[lapply(model_objects, class) == 'character']
  
  # Update list of succesfully fitted models
  success_models <- append(success_models,
                           model_objects[lapply(model_objects, class) != 'character'])
  
}

toc()
```

Plot the Weibull parameters. 

```{r process parameters and plot}
# Process parameters
final_parameters <- data.frame()
for(combi in names(success_models)){
  fixefect <- fixef(success_models[[combi]])
  ranef <- ranef(success_models[[combi]])
  
  final_parameters <- final_parameters %>% 
    bind_rows(  ranef %>%
                  mutate(tnumber= rownames(ranef),
                         phenotype_combo=combi) %>% 
                  mutate(A = A + fixefect[['A']],
                         B = B + fixefect[['B']]) %>%
                  mutate(a=10/(1+exp(-A)),b=500/(1+exp(-B))))
  
}

final_parameters %>%
  # separate(phenotype_combo, into=c('phenotype_from','phenotype_to'),sep='_to_') %>%
  # mutate(phenotype_to=mapvalues(phenotype_to, from=c('CD20+','CD3+','CD3+FoxP3+',
  #                                                    'CD68+','CD8+CD3+','PanCK+'),
  #                               to=c('B-cell','T-helper','Treg','Macrophages','CD8 T-cell','Cancer cell'))) %>%
  # mutate(phenotype_from=mapvalues(phenotype_from, from=c('CD20+','CD3+','CD3+FoxP3+',
                                  #                        'CD68+','CD8+CD3+','PanCK+'),
                                  # to=c('B-cell','T-helper','Treg','Macrophages','CD8 T-cell','Cancer cell'))) %>%
  # mutate(phenotype_to=paste('to',phenotype_to)) %>%
  ggplot(aes(x=a, y=b)) +
  geom_point(alpha=0.7, size=0.5) +
  # geom_density_2d() +
  theme_bw() + scale_y_log10() +
  xlab('Shape') + ylab('Scale') + scale_color_brewer(palette='Set2') +
  theme(legend.position='right')

ggsave(here('output/ShapeScaleScatterplot.png'))



```

